{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация поведения клиентов телеком оператора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from catboost import Pool\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1. Описание данных](#data_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv('./datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные без пропусков и предобработка не требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2. Разделение выборки](#train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как спрятанная тестовая выборка отсутствует, то исходные датасет следует разбить в пропорциях 60/20/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(users_df, test_size=0.4, shuffle=True, random_state=123456)\n",
    "df_valid, df_test = train_test_split(df_valid, test_size=0.5, shuffle=True, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_part(data, column_drop):\n",
    "    features = data.drop([column_drop], axis=1)\n",
    "    target = data[column_drop]\n",
    "    \n",
    "    return features, target\n",
    "    \n",
    "features_train, target_train = preprocess_data_part(data=df_train, column_drop='is_ultra')\n",
    "features_valid, target_valid = preprocess_data_part(data=df_valid, column_drop='is_ultra')\n",
    "features_test, target_test = preprocess_data_part(data=df_test, column_drop='is_ultra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевым признаком в данном датасете является столбец данных `is_ultra`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3. Исследование качества разных моделей.](#models_research)\n",
    "### [3.1 Классификатор дерева решений.](#decision_tree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree_classifier(features, target, max_depth, random_state, **kwargs):\n",
    "    model = DecisionTreeClassifier(random_state=random_state, max_depth=max_depth, **kwargs)\n",
    "    model.fit(features, target)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_decision_tree_classifier(features_train, target_train, features_valid, target_valid, max_param, random_state):\n",
    "    train_score = {}\n",
    "    valid_score = {}\n",
    "\n",
    "    for param in range(1, max_param):\n",
    "        for split_ in range(2, max_param):\n",
    "            for leaf_ in range(1, max_param):\n",
    "                model = train_decision_tree_classifier(features=features_train, target=target_train, max_depth=param, random_state=random_state, min_samples_split=split_, min_samples_leaf=leaf_)\n",
    "\n",
    "                train_score[f'{param}_{split_}_{leaf_}'] = model.score(features_train, target_train)\n",
    "                valid_score[f'{param}_{split_}_{leaf_}'] = model.score(features_valid, target_valid)\n",
    "\n",
    "    train_score = {param: score for param, score in sorted(train_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "    valid_score = {param: score for param, score in sorted(valid_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    top_train_param, top_train_score = list(train_score.items())[0]\n",
    "    top_valid_param, top_valid_score = list(valid_score.items())[0]\n",
    "    \n",
    "    return {'params_train': top_train_param, 'score_train': top_train_score, 'params_valid': top_valid_param, 'score_valid': top_valid_score} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_score = get_score_decision_tree_classifier(features_train, target_train, features_valid, target_valid, max_param=21, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат на обучающей выборке: с параметрами = 20_2_1, результат = 0.9880705394190872\n",
      "Лучший результат на валидационной выборке: с параметрами = 5_2_12, результат = 0.8118195956454122\n"
     ]
    }
   ],
   "source": [
    "print(f'Лучший результат на обучающей выборке: с параметрами = '\n",
    "      f'{decision_tree_score[\"params_train\"]}, результат = {decision_tree_score[\"score_train\"]}')\n",
    "\n",
    "print(f'Лучший результат на валидационной выборке: с параметрами = '\n",
    "      f'{decision_tree_score[\"params_valid\"]}, результат = {decision_tree_score[\"score_valid\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследовал классификатор *дерева решений*, лучший результат `0.8118195956454122` на валидационной выборке получил с параметрами **максимальной глубины дерева** `(max_depth)` **= 5**, **минимальным количеством примеров для разделения** `(min_samples_split)` **= 2** и **минимальным количеством объектов в листе** `(min_samples_leaf)` **= 12** точность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.2 Классификатор случайного леса](#random_forest_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest_classifier(features, target, n_estimators, random_state, **kwargs):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=123456, **kwargs)\n",
    "    model.fit(features, target)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_random_forest_classifier(features_train, \n",
    "                                       target_train, \n",
    "                                       features_valid, \n",
    "                                       target_valid, \n",
    "                                       start_estimators, max_estimators, step_estimators, \n",
    "                                       start_depth, max_depth, step_depth,\n",
    "                                       random_state, **kwargs):\n",
    "    train_score = {}\n",
    "    valid_score = {}\n",
    "    \n",
    "    for estimator in range(start_estimators, max_estimators, step_estimators):\n",
    "        for depth in range(start_depth, max_depth, step_depth):\n",
    "            model = train_random_forest_classifier(features=features_train, target=target_train, \n",
    "                                                   n_estimators=estimator, max_depth=depth, \n",
    "                                                   random_state=random_state, **kwargs)\n",
    "        \n",
    "            train_score[f'{estimator}_{depth}'] = model.score(features_train, target_train)\n",
    "            valid_score[f'{estimator}_{depth}'] = model.score(features_valid, target_valid)\n",
    "      \n",
    "    train_score = {param: score for param, score in sorted(train_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "    valid_score = {param: score for param, score in sorted(valid_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    top_train_param, top_train_score = list(train_score.items())[0]\n",
    "    top_valid_param, top_valid_score = list(valid_score.items())[0]\n",
    "    \n",
    "    return {'params_train': top_train_param, 'score_train': top_train_score, 'params_valid': top_valid_param, 'score_valid': top_valid_score} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_score = get_score_random_forest_classifier(features_train, target_train, \n",
    "                                                         features_valid, target_valid, \n",
    "                                                         start_estimators=1, max_estimators=257, step_estimators=10,\n",
    "                                                         start_depth=1, max_depth=21, step_depth=1,\n",
    "                                                         random_state=123456) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат на обучающей выборке: с параметрами = 41_20, результат = 0.9979253112033195\n",
      "Лучший результат на валидационной выборке: с параметрами = 91_8, результат = 0.8195956454121306\n"
     ]
    }
   ],
   "source": [
    "print(f'Лучший результат на обучающей выборке: с параметрами = '\n",
    "      f'{random_forest_score[\"params_train\"]}, результат = {random_forest_score[\"score_train\"]}')\n",
    "\n",
    "print(f'Лучший результат на валидационной выборке: с параметрами = '\n",
    "      f'{random_forest_score[\"params_valid\"]}, результат = {random_forest_score[\"score_valid\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследовал классификатор *случайного леса*, лучший результат `0.8195956454121306` на валидационной выборке получил с **количеством деревьев** `(n_estimators)` **= 91**, **максимальной глубиной дерева** `(max_depth)` **= 8**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.3 Классификатор логической регрессии.](#logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=123456, solver='lbfgs')\n",
    "logistic_regression_model.fit(features_train, target_train)\n",
    "\n",
    "logistic_regression_train_score = logistic_regression_model.score(features_train, target_train)\n",
    "logistic_regression_valid_score = logistic_regression_model.score(features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат на обучающей выборке: 0.7411825726141079\n",
      "Результат на валидационной выборке: 0.7402799377916018\n"
     ]
    }
   ],
   "source": [
    "print(f'Результат на обучающей выборке: {logistic_regression_train_score}')\n",
    "print(f'Результат на валидационной выборке: {logistic_regression_valid_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат применения классификации методом *логической регрессии* равен `0.7402799377916018` на валидационной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.4 Другие методы классификации.](#other_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_train_score = {}\n",
    "neigh_valid_score = {}\n",
    "\n",
    "for eighbor in range (1, 21):\n",
    "    neigh_model = KNeighborsClassifier(n_neighbors=eighbor)\n",
    "    neigh_model.fit(features_train, target_train)\n",
    "\n",
    "    neigh_train_score[eighbor] = neigh_model.score(features_train, target_train)\n",
    "    neigh_valid_score[eighbor] = neigh_model.score(features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат на обучающей выборке: с параметрами = 1, результат = 1.0\n",
      "Результат на валидационной выборке: с параметрами = 6, результат = 0.7511664074650077\n"
     ]
    }
   ],
   "source": [
    "neigh_train = {estimators: score for estimators, score in sorted(neigh_train_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "neigh_valid = {estimators: score for estimators, score in sorted(neigh_valid_score.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "neigh_train_param, neigh_train_score = list(neigh_train.items())[0]\n",
    "neigh_valid_param, neigh_valid_score = list(neigh_valid.items())[0]\n",
    "\n",
    "print(f'Результат на обучающей выборке: с параметрами = {neigh_train_param}, результат = {neigh_train_score}')\n",
    "print(f'Результат на валидационной выборке: с параметрами = {neigh_valid_param}, результат = {neigh_valid_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат применения метода *K-ближайших соседей* **с количеством соседей** `n_neighbors` **= 6** равен `0.7511664074650077` на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат на обучающей выборке: 0.7847510373443983\n",
      "Результат на валидационной выборке: 0.7729393468118196\n"
     ]
    }
   ],
   "source": [
    "gauss_train_score = {}\n",
    "gauss_valid_score = {}\n",
    "\n",
    "gauss_model = GaussianNB()\n",
    "gauss_model.fit(features_train, target_train)\n",
    "\n",
    "gauss_train_score = gauss_model.score(features_train, target_train)\n",
    "gauss_valid_score = gauss_model.score(features_valid, target_valid)\n",
    "\n",
    "print(f'Результат на обучающей выборке: {gauss_train_score}')\n",
    "print(f'Результат на валидационной выборке: {gauss_valid_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат применения метода *Gaussian Naive Bayes (GaussianNB)* равен `0.7729393468118196` на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7795643\ttest: 0.7651633\tbest: 0.7651633 (0)\ttotal: 52.2ms\tremaining: 52.1s\n",
      "100:\tlearn: 0.8329876\ttest: 0.8211509\tbest: 0.8258165 (92)\ttotal: 249ms\tremaining: 2.22s\n",
      "200:\tlearn: 0.8651452\ttest: 0.8071540\tbest: 0.8258165 (92)\ttotal: 445ms\tremaining: 1.77s\n",
      "300:\tlearn: 0.8947095\ttest: 0.8102644\tbest: 0.8258165 (92)\ttotal: 644ms\tremaining: 1.5s\n",
      "400:\tlearn: 0.9133817\ttest: 0.7978227\tbest: 0.8258165 (92)\ttotal: 831ms\tremaining: 1.24s\n",
      "500:\tlearn: 0.9263485\ttest: 0.7947123\tbest: 0.8258165 (92)\ttotal: 1.04s\tremaining: 1.03s\n",
      "600:\tlearn: 0.9377593\ttest: 0.7884914\tbest: 0.8258165 (92)\ttotal: 1.34s\tremaining: 893ms\n",
      "700:\tlearn: 0.9481328\ttest: 0.7838258\tbest: 0.8258165 (92)\ttotal: 1.59s\tremaining: 679ms\n",
      "800:\tlearn: 0.9548755\ttest: 0.7838258\tbest: 0.8258165 (92)\ttotal: 1.89s\tremaining: 469ms\n",
      "900:\tlearn: 0.9616183\ttest: 0.7807154\tbest: 0.8258165 (92)\ttotal: 2.18s\tremaining: 240ms\n",
      "999:\tlearn: 0.9725104\ttest: 0.7744946\tbest: 0.8258165 (92)\ttotal: 2.37s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8258164852\n",
      "bestIteration = 92\n",
      "\n",
      "Shrink model to first 93 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x13a1e5580>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pool = Pool(features_train, target_train)\n",
    "valid_pool = Pool(features_valid, target_valid)\n",
    "\n",
    "cat_model = CatBoostClassifier(iterations=1000, learning_rate=0.05, eval_metric='Accuracy', random_state=123456)\n",
    "cat_model.fit(train_pool, eval_set=valid_pool, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_valid_score = cat_model.score(features_valid, target_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат применения классификатора *CatBoostClassifier* равен `0.8258164852` на валидационной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4. Проверка моделей на тестовой выборке.](#testing_models)\n",
    "### [4.1 Тестирование модели дерева решений.](#test_decision_tree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры модели дерева решений: max_depth=5, min_samples_split=2, min_samples_leaf=12\n"
     ]
    }
   ],
   "source": [
    "decision_tree_params = [int(param) for param in decision_tree_score['params_valid'].split('_')]\n",
    "\n",
    "print(f'Параметры модели дерева решений: max_depth={decision_tree_params[0]}, ' \n",
    "      f'min_samples_split={decision_tree_params[1]}, ' \n",
    "      f'min_samples_leaf={decision_tree_params[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = train_decision_tree_classifier(features=features_train, target=target_train, \n",
    "                                                     max_depth=decision_tree_params[0], \n",
    "                                                     min_samples_split=decision_tree_params[1], \n",
    "                                                     min_samples_leaf=decision_tree_params[2],\n",
    "                                                     random_state=123456)\n",
    "\n",
    "decision_tree_test_score = decision_tree_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели дерева решений на валидационной выборке: 0.8118195956454122\n",
      "Результат модели дерева решений на тестовой выборке: 0.8118195956454122\n",
      "Расхождение модели 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Результат модели дерева решений на валидационной выборке: {decision_tree_score[\"score_valid\"]}')\n",
    "print(f'Результат модели дерева решений на тестовой выборке: {decision_tree_test_score}')\n",
    "print(f'Расхождение модели {(decision_tree_score[\"score_valid\"] - decision_tree_test_score)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели дерева решений на тестовой выборке показала аналогичные результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.2 Тестирование модели случайного леса.](#test_random_forest_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры модели случайного дерева: n_estimators=91, max_depth=8\n"
     ]
    }
   ],
   "source": [
    "random_forest_params = [int(param) for param in random_forest_score['params_valid'].split('_')]\n",
    "\n",
    "print(f'Параметры модели случайного дерева: n_estimators={random_forest_params[0]}, ' \n",
    "      f'max_depth={random_forest_params[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = train_random_forest_classifier(features=features_train, target=target_train, \n",
    "                                                     n_estimators=random_forest_params[0], max_depth=random_forest_params[1],\n",
    "                                                     random_state=123456)\n",
    "\n",
    "random_forest_test_score = random_forest_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели дерева решений на валидационной выборке: 0.8195956454121306\n",
      "Результат модели дерева решений на тестовой выборке: 0.8180404354587869\n",
      "Расхождение модели 0.16%\n"
     ]
    }
   ],
   "source": [
    "print(f'Результат модели дерева решений на валидационной выборке: {random_forest_score[\"score_valid\"]}')\n",
    "print(f'Результат модели дерева решений на тестовой выборке: {random_forest_test_score}')\n",
    "print(f'Расхождение модели {(random_forest_score[\"score_valid\"] - random_forest_test_score):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели случайного леса на тестовой выборке показала небольшое расхождение с результатами на валидационной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.3 Тестирование модели логической регрессии.](#test_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_test_score = logistic_regression_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели логической регрессии на валидационной выборке: 0.7402799377916018\n",
      "Результат модели логической регрессии на тестовой выборке: 0.7651632970451011\n",
      "Расхождение модели -2.49%\n"
     ]
    }
   ],
   "source": [
    "print(f'Результат модели логической регрессии на валидационной выборке: {logistic_regression_valid_score}')\n",
    "print(f'Результат модели логической регрессии на тестовой выборке: {logistic_regression_test_score}')\n",
    "print(f'Расхождение модели {(logistic_regression_valid_score - logistic_regression_test_score):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели логической регрессии на тестовой выборке показала небольшое расхождение с результатами на валидационной выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.4 Тестирование других методов классификации.](#test_other_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры модели K-ближайших соседей: n_neighbors=20\n"
     ]
    }
   ],
   "source": [
    "print(f'Параметры модели K-ближайших соседей: n_neighbors={eighbor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors_model = KNeighborsClassifier(n_neighbors=eighbor)\n",
    "kneighbors_model.fit(features_train, target_train)\n",
    "\n",
    "kneighbors_test_score = kneighbors_model.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели K-ближайших соседей на валидационной выборке: 0.7511664074650077\n",
      "Результат модели K-ближайших соседей на тестовой выборке: 0.7822706065318819\n",
      "Расхождение модели -3.11%\n"
     ]
    }
   ],
   "source": [
    "print(f'Результат модели K-ближайших соседей на валидационной выборке: {neigh_valid_score}')\n",
    "print(f'Результат модели K-ближайших соседей на тестовой выборке: {kneighbors_test_score}')\n",
    "print(f'Расхождение модели {(neigh_valid_score - kneighbors_test_score):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели K-ближайших соседей на тестовой выборке показала небольшое расхождение с результатами на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели Gaussian Naive Bayes на валидационной выборке: 0.7729393468118196\n",
      "Результат модели Gaussian Naive Bayes на тестовой выборке: 0.7900466562986003\n",
      "Расхождение модели -1.71%\n"
     ]
    }
   ],
   "source": [
    "gauss_test_score = gauss_model.score(features_test, target_test)\n",
    "\n",
    "print(f'Результат модели Gaussian Naive Bayes на валидационной выборке: {gauss_valid_score}')\n",
    "print(f'Результат модели Gaussian Naive Bayes на тестовой выборке: {gauss_test_score}')\n",
    "print(f'Расхождение модели {(gauss_valid_score - gauss_test_score):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели Gaussian Naive Bayes на тестовой выборке показала небольшое расхождение с результатами на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат модели CatBoostClassifier на валидационной выборке: 0.8258164852255054\n",
      "Результат модели CatBoostClassifier на тестовой выборке: 0.8149300155520995\n",
      "Расхождение модели 1.09%\n"
     ]
    }
   ],
   "source": [
    "cat_test_score = cat_model.score(features_test, target_test)\n",
    "\n",
    "print(f'Результат модели CatBoostClassifier на валидационной выборке: {cat_valid_score}')\n",
    "print(f'Результат модели CatBoostClassifier на тестовой выборке: {cat_test_score}')\n",
    "print(f'Расхождение модели {(cat_valid_score - cat_test_score):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка модели Gaussian Naive Bayes на тестовой выборке показала небольшое расхождение с результатами на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_rank = {'CatBoostClassifier': cat_test_score, \n",
    "               'GaussianNB': gauss_test_score, \n",
    "               'KNeighborsClassifier': kneighbors_test_score, \n",
    "               'LogisticRegression': logistic_regression_test_score, \n",
    "               'RandomForestClassifier': random_forest_test_score, \n",
    "               'DecisionTreeClassifier': decision_tree_test_score}\n",
    "\n",
    "models_rank = {model_name: score for model_name, score in sorted(models_rank.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier': 0.8180404354587869,\n",
       " 'CatBoostClassifier': 0.8149300155520995,\n",
       " 'DecisionTreeClassifier': 0.8118195956454122,\n",
       " 'GaussianNB': 0.7900466562986003,\n",
       " 'KNeighborsClassifier': 0.7822706065318819,\n",
       " 'LogisticRegression': 0.7651632970451011}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разница между двумя наибольшими результатами: 0.31%\n"
     ]
    }
   ],
   "source": [
    "print(f'Разница между двумя наибольшими результатами: {(list(models_rank.values())[0] - list(models_rank.values())[1]):0.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5. Проверка моделей на вменяемость.](#sanity_check_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки моделей на можно сравнить со случайной моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат случайной модели на тестовой выборке: 0.4976671850699845\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='uniform')\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "\n",
    "dummy_valid = dummy_clf.score(features_valid, target_valid)\n",
    "dummy_test = dummy_clf.score(features_test, target_test)\n",
    "\n",
    "print(f'Результат случайной модели на тестовой выборке: {dummy_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат случайной модели на тестовой выборке: 0.7216174183514774\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "\n",
    "dummy_valid = dummy_clf.score(features_valid, target_valid)\n",
    "dummy_test = dummy_clf.score(features_test, target_test)\n",
    "\n",
    "print(f'Результат случайной модели на тестовой выборке: {dummy_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат случайной модели на тестовой выборке равен примерно 50%, что доказывает вменяемость всех рассмотренных моделей. По результатам тестированиям модели можно выделить две с наибольшими результатами. Это случайны лес `RandomForestClassifier` и CatBoost `CatBoostClassifier`. Так как разница между ними не велика и скорость обучения модели CatBoost выше, то данная модель наиболее предпочтительна."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
